# Policy-Retention-Prediction
Travelers Stat-a-thon 2019 Competition (Kaggle Rank 3)

New Approaches tried:
1) Target Encoding cities from zipcode feature
2) Weighted Stacked Ensemble of Tree Based Classifiers and Neural Network
3) Superlearner inside stacked ensemble
4) Parameter optimization, which was the most useful in case of Gradient Boosted Classifier
5) Clustering locations based on Lat, Long using K-means Clustering. Also tried using DBSCAN but fell short of computational power capable of handling it.

Achieved Rank 3 (solo) on Kaggle. https://www.kaggle.com/c/TRVstatathon/leaderboard.

This was my first Kaggle Competition, and a great learning experience. Thanks to University of Connecticut and New England Statistical Society for this interesting data and for the invitation to attend NESS Conference.

